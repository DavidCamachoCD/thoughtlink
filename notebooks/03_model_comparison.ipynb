{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ThoughtLink \u2014 Model Comparison\n",
    "\n",
    "Compare all trained models: 4 sklearn baselines, hierarchical 2-stage classifier, and EEGNet CNN.\n",
    "\n",
    "**Metrics**: Accuracy, Cohen's Kappa, confusion matrices, latency vs accuracy tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, str(Path('.').resolve().parent / 'src'))\n",
    "from thoughtlink.data.loader import CLASS_NAMES\n",
    "\n",
    "results_dir = Path('../results')\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)\n",
    "print(f'Results directory: {results_dir.resolve()}')\n",
    "print(f'Files: {[f.name for f in results_dir.glob(\"*\")]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline results\n",
    "rows = []\n",
    "\n",
    "baseline_path = results_dir / 'baseline_results.json'\n",
    "if baseline_path.exists():\n",
    "    with open(baseline_path) as f:\n",
    "        baseline = json.load(f)\n",
    "    for name, metrics in baseline['multiclass'].items():\n",
    "        rows.append({\n",
    "            'Model': name, 'Accuracy': metrics['accuracy'],\n",
    "            'Kappa': metrics['kappa'], 'Type': 'Baseline'\n",
    "        })\n",
    "\n",
    "# Load hierarchical results\n",
    "hier_path = results_dir / 'hierarchical_results.json'\n",
    "if hier_path.exists():\n",
    "    with open(hier_path) as f:\n",
    "        hier = json.load(f)\n",
    "    rows.append({\n",
    "        'Model': 'hierarchical', 'Accuracy': hier['accuracy'],\n",
    "        'Kappa': hier['kappa'], 'Type': 'Hierarchical',\n",
    "        'Stage1 Acc': hier.get('stage1_accuracy'),\n",
    "        'FTR': hier.get('false_trigger_rate'),\n",
    "    })\n",
    "\n",
    "# Load CNN results\n",
    "cnn_path = results_dir / 'cnn_results.json'\n",
    "if cnn_path.exists():\n",
    "    with open(cnn_path) as f:\n",
    "        cnn = json.load(f)\n",
    "    rows.append({\n",
    "        'Model': 'eegnet_cnn', 'Accuracy': cnn['accuracy'],\n",
    "        'Kappa': cnn['kappa'], 'Type': 'CNN',\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "type_colors = {'Baseline': '#3b82f6', 'Hierarchical': '#22c55e', 'CNN': '#f97316'}\n",
    "colors = [type_colors.get(t, '#888') for t in df['Type']]\n",
    "\n",
    "bars = ax.barh(df['Model'], df['Accuracy'], color=colors, edgecolor='white', linewidth=0.5)\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('5-Class Intent Decoding Accuracy')\n",
    "ax.axvline(0.2, color='red', ls='--', lw=1, label='Chance (20%)')\n",
    "ax.set_xlim(0, 1.0)\n",
    "\n",
    "for bar, acc in zip(bars, df['Accuracy']):\n",
    "    ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "            f'{acc:.1%}', va='center', fontsize=10)\n",
    "\n",
    "# Legend for model types\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=c, label=t) for t, c in type_colors.items()]\n",
    "legend_elements.append(plt.Line2D([0], [0], color='red', ls='--', label='Chance'))\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../results/model_accuracy_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load data and generate predictions for confusion matrices\n",
    "from thoughtlink.data.loader import load_all\n",
    "from thoughtlink.data.splitter import split_by_subject\n",
    "from thoughtlink.preprocessing.eeg import preprocess_all\n",
    "from thoughtlink.preprocessing.windowing import windows_from_samples\n",
    "from thoughtlink.features.eeg_features import extract_features_from_windows\n",
    "\n",
    "samples = load_all()\n",
    "_, test_samples = split_by_subject(samples, test_size=0.2)\n",
    "preprocess_all(test_samples)\n",
    "X_test_windows, y_test, _ = windows_from_samples(test_samples)\n",
    "X_test = extract_features_from_windows(X_test_windows)\n",
    "\n",
    "# Load models\n",
    "models_to_plot = {}\n",
    "best_baseline_path = results_dir / 'best_baseline.pkl'\n",
    "if best_baseline_path.exists():\n",
    "    with open(best_baseline_path, 'rb') as f:\n",
    "        models_to_plot['Best Baseline'] = pickle.load(f)\n",
    "\n",
    "hier_model_path = results_dir / 'hierarchical_model.pkl'\n",
    "if hier_model_path.exists():\n",
    "    with open(hier_model_path, 'rb') as f:\n",
    "        models_to_plot['Hierarchical'] = pickle.load(f)\n",
    "\n",
    "n_models = len(models_to_plot)\n",
    "if n_models > 0:\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(6 * n_models, 5))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (name, model) in zip(axes, models_to_plot.items()):\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(cm, display_labels=CLASS_NAMES)\n",
    "        disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "        ax.set_title(name)\n",
    "        ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right', fontsize=8)\n",
    "        ax.set_yticklabels(CLASS_NAMES, fontsize=8)\n",
    "\n",
    "    fig.suptitle('Confusion Matrices', fontsize=14, fontweight='bold')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('../results/confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No models available for confusion matrices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Latency vs Accuracy Tradeoff\n",
    "\n",
    "Key for bonus evaluation criterion: _\"quantify latency\u2013accuracy tradeoffs\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from thoughtlink.features.eeg_features import extract_window_features\n",
    "\n",
    "# Benchmark each model's inference latency\n",
    "window = np.random.randn(500, 6).astype(np.float32) * 10\n",
    "features = extract_window_features(window)\n",
    "\n",
    "latency_data = []\n",
    "\n",
    "for name, model in models_to_plot.items():\n",
    "    times = []\n",
    "    for _ in range(100):\n",
    "        t0 = time.perf_counter()\n",
    "        model.predict_proba(features.reshape(1, -1))\n",
    "        times.append((time.perf_counter() - t0) * 1000)\n",
    "    acc = df.loc[df['Model'].str.contains(name.split()[0].lower()), 'Accuracy']\n",
    "    acc_val = acc.values[0] if len(acc) > 0 else 0\n",
    "    latency_data.append({'Model': name, 'Latency (ms)': np.mean(times), 'Accuracy': acc_val})\n",
    "\n",
    "lat_df = pd.DataFrame(latency_data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "scatter = ax.scatter(lat_df['Latency (ms)'], lat_df['Accuracy'],\n",
    "                     s=200, c=['#3b82f6', '#22c55e'][:len(lat_df)],\n",
    "                     edgecolors='white', linewidth=2, zorder=5)\n",
    "\n",
    "for _, row in lat_df.iterrows():\n",
    "    ax.annotate(row['Model'], (row['Latency (ms)'], row['Accuracy']),\n",
    "                textcoords='offset points', xytext=(10, 5), fontsize=10)\n",
    "\n",
    "ax.axhline(0.2, color='red', ls='--', lw=1, alpha=0.5, label='Chance')\n",
    "ax.axvline(50, color='orange', ls='--', lw=1, alpha=0.5, label='50ms target')\n",
    "ax.set_xlabel('Inference Latency (ms)')\n",
    "ax.set_ylabel('5-Class Accuracy')\n",
    "ax.set_title('Latency vs Accuracy Tradeoff')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../results/latency_vs_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "lat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Space Visualization (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thoughtlink.viz.latent_viz import plot_latent_report\n",
    "\n",
    "fig = plot_latent_report(\n",
    "    X_test, y_test,\n",
    "    class_names=CLASS_NAMES,\n",
    "    title='ThoughtLink \u2014 Feature Space Analysis',\n",
    "    save_path='../results/feature_space_analysis.png',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hierarchical Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hier_path.exists():\n",
    "    with open(hier_path) as f:\n",
    "        hier = json.load(f)\n",
    "    \n",
    "    print('=== Hierarchical Model Results ===')\n",
    "    print(f\"Overall Accuracy:      {hier['accuracy']:.1%}\")\n",
    "    print(f\"Cohen's Kappa:         {hier['kappa']:.3f}\")\n",
    "    print(f\"Stage 1 Accuracy:      {hier.get('stage1_accuracy', 'N/A')}\")\n",
    "    print(f\"False Trigger Rate:    {hier.get('false_trigger_rate', 'N/A')}\")\n",
    "    print()\n",
    "    print('Stage 1 (Relax vs Active) acts as a gate that filters')\n",
    "    print('false triggers before Stage 2 (4-class) runs.')\n",
    "    print(f'This reduces false triggers to {hier.get(\"false_trigger_rate\", \"N/A\")} during rest periods.')\n",
    "else:\n",
    "    print('Hierarchical results not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "| Finding | Detail |\n",
    "|---------|--------|\n",
    "| **Best model** | See table above |\n",
    "| **Inference latency** | All models well under 50ms target |\n",
    "| **Hierarchical advantage** | Binary gate reduces false triggers during rest |\n",
    "| **Feature space** | t-SNE shows class separability with 42 EEG features |\n",
    "| **Trade-off** | Simple sklearn models offer best latency-accuracy ratio for real-time BCI |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
